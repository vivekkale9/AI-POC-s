{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, collect_set, collect_list\n",
    "from bson import ObjectId\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables (Databricks can also use secrets management)\n",
    "load_dotenv()\n",
    "\n",
    "# Access environment variables\n",
    "mongo_uri = \"mongodb+srv://root:root@learningmongo.cr2lsf3.mongodb.net\"\n",
    "database = \"mRounds\"\n",
    "\n",
    "# Import Spark session\n",
    "from sparkConfig import spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bo_for_product(product=None):\n",
    "    try:\n",
    "        masterbo_df = spark.read.format(\"mongo\") \\\n",
    "            .option(\"uri\", f\"{mongo_uri}/{database}.MasterBO?retryWrites=true&w=majority&appName=learningMongo\") \\\n",
    "            .load()\n",
    "        \n",
    "        if product:\n",
    "            # Filter by product and select BO\n",
    "            result = masterbo_df.filter(col(\"product\") == product) \\\n",
    "                .select(\"_id\", \"product\", \"BusinessObject\")\n",
    "\n",
    "            # Convert to list of dictionaries\n",
    "            bo_list = [row.asDict() for row in result.collect()]\n",
    "\n",
    "            if not bo_list:\n",
    "                return {\"message\": f\"No BOs found for product '{product}'\"}\n",
    "\n",
    "            return bo_list\n",
    "        else:\n",
    "            # Group by product and collect BusinessObjects\n",
    "            result = masterbo_df.groupBy(\"product\") \\\n",
    "                .agg(collect_list(\"BusinessObject\").alias(\"BusinessObjects\")) \\\n",
    "                .select(\"product\", \"BusinessObjects\")\n",
    "\n",
    "            # Convert to list of dictionaries\n",
    "            product_bo_list = [row.asDict() for row in result.collect()]\n",
    "\n",
    "            if not product_bo_list:\n",
    "                return {\"message\": \"No products or BOs found\"}\n",
    "\n",
    "            return product_bo_list\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        return {\"error\": \"An internal error occurred\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: An error occurred while calling o51.load.\n",
      ": org.apache.spark.SparkClassNotFoundException: [DATA_SOURCE_NOT_FOUND] Failed to find the data source: mongo. Please find packages at `https://spark.apache.org/third-party-projects.html`.\n",
      "\tat org.apache.spark.sql.errors.QueryExecutionErrors$.dataSourceNotFoundError(QueryExecutionErrors.scala:724)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:647)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSourceV2(DataSource.scala:697)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:208)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.lang.ClassNotFoundException: mongo.DefaultSource\n",
      "\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:476)\n",
      "\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:594)\n",
      "\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:527)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$5(DataSource.scala:633)\n",
      "\tat scala.util.Try$.apply(Try.scala:213)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$4(DataSource.scala:633)\n",
      "\tat scala.util.Failure.orElse(Try.scala:224)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:633)\n",
      "\t... 15 more\n",
      "\n",
      "{'error': 'An internal error occurred'}\n"
     ]
    }
   ],
   "source": [
    "result = get_bo_for_product(\"mRounds\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
